from typing import List, Dict, Any

from .embeddings_client import EmbeddingsClient
from .vector_db_client import VectorDBClient
from .llm_client import LLMClient
from .text_utils import normalize_question


class RAGPipeline:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π RAG-–ø–∞–π–ø–ª–∞–π–Ω:
    - embed –∑–∞–ø—Ä–æ—Å–∞,
    - –ø–æ–∏—Å–∫ –ø–æ Qdrant,
    - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
    """

    def __init__(self, top_k: int = 5):
        self.emb_client = EmbeddingsClient()
        self.vec_client = VectorDBClient(vector_size=1536)
        self.llm_client = LLMClient()
        self.top_k = top_k

    def retrieve(self, question: str) -> List[Dict[str, Any]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç top_k —á–∞–Ω–∫–æ–≤ –∏–∑ Qdrant –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
        [
            {
                "text": "...",
                "metadata": {...},
                "score": 0.98,
            },
            ...
        ]
        """

        # 1. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–æ–ø—Ä–æ—Å (–∏—Å–ø—Ä–∞–≤–ª—è–µ–º —á–∞—Å—Ç—ã–µ –æ–ø–µ—á–∞—Ç–∫–∏)
        normalized_question = normalize_question(question)

        # 2. –î–µ–ª–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ —É–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        query_vector = self.emb_client.embed_text(normalized_question)

        # 3. –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –≤–µ–∫—Ç–æ—Ä–∞ –≤ Qdrant
        results = self.vec_client.search(
            query_vector=query_vector,
            limit=self.top_k,
        )

        # 4. –ü—Ä–∏–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫ —É–¥–æ–±–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
        docs: List[Dict[str, Any]] = []
        for hit in results:
            payload = hit.payload or {}
            text = payload.get("text", "")
            docs.append(
                {
                    "text": text,
                    "metadata": payload,
                    "score": hit.score,
                }
            )

        return docs

    def answer_question(self, question: str, temperature: float = 0.1) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª RAG:
        - –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–æ–ø—Ä–æ—Å (–∏—Å–ø—Ä–∞–≤–ª—è–µ–º —á–∞—Å—Ç—ã–µ –æ–ø–µ—á–∞—Ç–∫–∏),
        - –∏—â–µ–º top_k —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤,
        - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å –∏ —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ –≤ LLM,
        - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç + –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.
        """

        # 1. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–æ–ø—Ä–æ—Å (–¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ –¥–ª—è LLM)
        normalized_question = normalize_question(question)

        # 2. –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ Qdrant (retrieve —É–∂–µ —Å–æ–±–∏—Ä–∞–µ—Ç –∏—Ö –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
        docs: List[Dict[str, Any]] = self.retrieve(question)

        # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É—è –ù–û–†–ú–ê–õ–ò–ó–û–í–ê–ù–ù–´–ô –≤–æ–ø—Ä–æ—Å –∏ —á–∞–Ω–∫–∏ –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        answer = self.llm_client.generate_answer(
            question=normalized_question,
            context_chunks=docs,
            temperature=temperature,
        )

        # 4. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å—ë, —á—Ç–æ –Ω—É–∂–Ω–æ UI
        return {
            "answer": answer,
            "question": question,
            "normalized_question": normalized_question,
            "documents": docs,  # üîπ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ Streamlit
            "docs": docs,
        }



if __name__ == "__main__":
    pipeline = RAGPipeline(top_k=4)
    user_question = "How can I connect to corporate Wi-Fi on Windows?"

    result = pipeline.answer_question(user_question)

    print("QUESTION:")
    print(result["question"])
    print("\nANSWER:")
    print(result["answer"])
    print("\n--- CONTEXT DOCS ---")
    for i, doc in enumerate(result["documents"], start=1):
        print(f"\n[Doc {i} | score={doc['score']:.3f}]")
        print(doc["text"][:300], "...")
